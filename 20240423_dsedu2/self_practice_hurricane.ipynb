{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f27a61d3",
   "metadata": {},
   "source": [
    "# 실습 - 허리케인 피해 지역 구분하기\n",
    "\n",
    "\n",
    "## 개요\n",
    "  - 허리케인이 지나간 위치의 위성 이미지를 보고, 피해 여부를 판단하는 모델을 만들어 봅시다.\n",
    "\n",
    "## 목표\n",
    "  - validation dataset 에 대해 95% 이상의 정확도를 가지는 것이 목표입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c0fee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import zipfile\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a8920c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_extract_data():\n",
    "    url = 'https://storage.googleapis.com/download.tensorflow.org/data/certificate/satellitehurricaneimages.zip'\n",
    "    urllib.request.urlretrieve(url, 'satellitehurricaneimages.zip')\n",
    "    with zipfile.ZipFile('satellitehurricaneimages.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "\n",
    "download_and_extract_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268a3fd2",
   "metadata": {},
   "source": [
    "# 1. 이미지 전처리\n",
    "\n",
    "  - image 전처리를 담당하는 함수를 만들어 봅시다.\n",
    "  - 간단한 normalize 만 수행해도 충분합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46f13097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, label):\n",
    "    # 함수 내용을 작성하세요.\n",
    "    image = image  / 255\n",
    "\n",
    "    max = tf.math.reduce_max(image)\n",
    "    (image - min) / (max - min)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3a6192",
   "metadata": {},
   "source": [
    "# 2. 데이터 준비\n",
    "\n",
    "  - 다운로드 받은 데이터를 읽어서 준비합니다.\n",
    "  - 위에서 정의한 preprocess 함수를 이용하여 전처리를 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96d74e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 files belonging to 2 classes.\n",
      "Found 2000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory='train/',\n",
    "    image_size= (IMG_SIZE,IMG_SIZE)\n",
    "    , batch_size=BATCH_SIZE)\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory='validation/',\n",
    "    image_size= (IMG_SIZE,IMG_SIZE)\n",
    "    , batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "train_ds = train_ds.map(\n",
    "        preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE).prefetch(\n",
    "        tf.data.experimental.AUTOTUNE)\n",
    "val_ds = val_ds.map(\n",
    "        preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494b2133",
   "metadata": {},
   "source": [
    "# 3. 모델 정의\n",
    "\n",
    "  - 모델 모양을 정의합니다.\n",
    "  - Input, Output 모양을 유의하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33824a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # 함수 내용을 작성하세요.\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0050399",
   "metadata": {},
   "source": [
    "# 4. 모델 컴파일\n",
    "\n",
    "  - 학습 방법을 정의하세요\n",
    "  - loss, optimizer, metrics 를 올바르게 지정하면 충분합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "846c32a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    # 함수 내용을 작성하세요.\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e0c79f",
   "metadata": {},
   "source": [
    "# 5. 모델 학습\n",
    "\n",
    "  - 학습을 위한 epoch, batch_size 등을 설정하세요.\n",
    "  - 이 외에 사용하고 싶은 기법들은 자유롭게 도입하셔도 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cc6f9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 88ms/step - accuracy: 0.9626 - loss: 0.0951 - val_accuracy: 0.9320 - val_loss: 0.1835\n",
      "Epoch 2/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 87ms/step - accuracy: 0.9685 - loss: 0.0831 - val_accuracy: 0.9450 - val_loss: 0.1691\n",
      "Epoch 3/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 87ms/step - accuracy: 0.9746 - loss: 0.0728 - val_accuracy: 0.9610 - val_loss: 0.1133\n",
      "Epoch 4/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 90ms/step - accuracy: 0.9821 - loss: 0.0569 - val_accuracy: 0.9455 - val_loss: 0.1395\n",
      "Epoch 5/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 84ms/step - accuracy: 0.9787 - loss: 0.0640 - val_accuracy: 0.9580 - val_loss: 0.1164\n",
      "Epoch 6/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 89ms/step - accuracy: 0.9863 - loss: 0.0411 - val_accuracy: 0.9610 - val_loss: 0.1312\n",
      "Epoch 7/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 90ms/step - accuracy: 0.9859 - loss: 0.0377 - val_accuracy: 0.9645 - val_loss: 0.1637\n",
      "Epoch 8/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 89ms/step - accuracy: 0.9936 - loss: 0.0231 - val_accuracy: 0.9605 - val_loss: 0.1569\n",
      "Epoch 9/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 89ms/step - accuracy: 0.9861 - loss: 0.0385 - val_accuracy: 0.9620 - val_loss: 0.1463\n",
      "Epoch 10/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 86ms/step - accuracy: 0.9925 - loss: 0.0237 - val_accuracy: 0.9545 - val_loss: 0.1634\n",
      "Epoch 11/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 84ms/step - accuracy: 0.9964 - loss: 0.0167 - val_accuracy: 0.9670 - val_loss: 0.1313\n",
      "Epoch 12/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 90ms/step - accuracy: 0.9981 - loss: 0.0100 - val_accuracy: 0.9570 - val_loss: 0.1861\n",
      "Epoch 13/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 89ms/step - accuracy: 0.9937 - loss: 0.0192 - val_accuracy: 0.9510 - val_loss: 0.1827\n",
      "Epoch 14/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 84ms/step - accuracy: 0.9887 - loss: 0.0273 - val_accuracy: 0.9585 - val_loss: 0.1426\n",
      "Epoch 15/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 85ms/step - accuracy: 0.9956 - loss: 0.0153 - val_accuracy: 0.9670 - val_loss: 0.1278\n",
      "Epoch 16/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 84ms/step - accuracy: 0.9968 - loss: 0.0093 - val_accuracy: 0.9630 - val_loss: 0.1562\n",
      "Epoch 17/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 83ms/step - accuracy: 0.9982 - loss: 0.0058 - val_accuracy: 0.9665 - val_loss: 0.1623\n",
      "Epoch 18/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 83ms/step - accuracy: 0.9979 - loss: 0.0078 - val_accuracy: 0.9675 - val_loss: 0.1648\n",
      "Epoch 19/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 83ms/step - accuracy: 0.9988 - loss: 0.0058 - val_accuracy: 0.9655 - val_loss: 0.1834\n",
      "Epoch 20/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 91ms/step - accuracy: 0.9999 - loss: 0.0013 - val_accuracy: 0.9700 - val_loss: 0.1868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1dfab6fc190>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=20,\n",
    "        batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a477f2",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "\n",
    "- 이미지를 View 합니다.\n",
    "- model 로 predict 를 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fb2e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Take one batch of images and labels\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory='validation/',\n",
    "    image_size= (IMG_SIZE,IMG_SIZE)\n",
    "    , batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cc2ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(val_ds.shuffle(buffer_size=10000)))\n",
    "\n",
    "data_index = 0\n",
    "\n",
    "selected_image = images[data_index].numpy().astype(\"uint8\")\n",
    "selected_label = labels[data_index].numpy()\n",
    "\n",
    "image_to_predict = np.expand_dims(selected_image/255, axis=0)\n",
    "\n",
    "# Make a prediction\n",
    "predictions = model.predict(image_to_predict)\n",
    "predicted_label = int(predictions.round())\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(selected_image)\n",
    "class_names = val_ds.class_names\n",
    "plt.title(f\"True Label: {class_names[selected_label]}, Predicted: {class_names[predicted_label]}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289c40db",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "\n",
    "- transfer learning 을 이용해서도 풀어봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579cb971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자유롭게 작성하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079174c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc33104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ce6a67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
